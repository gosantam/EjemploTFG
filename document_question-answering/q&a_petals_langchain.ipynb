{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPFFiGZkal0oVUUtdFfF1ek",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gosantam/EjemploTFG/blob/master/document_question-answering/q%26a_petals_langchain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How to use bigger LLM in Colab\n",
        "\n",
        "- Using [Petals](https://python.langchain.com/docs/integrations/llms/petals) and [LangChain](https://www.langchain.com/) to test Llama2-70B model\n",
        "\n",
        "- [Combining Petals and LangChain](https://python.langchain.com/docs/integrations/llms/petals)"
      ],
      "metadata": {
        "id": "CIlTpb00a2sM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Libraries"
      ],
      "metadata": {
        "id": "zTqN6iMPbbMT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Swy4VbxnanHQ"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "# requirements\n",
        "!pip install langchain\n",
        "!pip install petals\n",
        "!pip install --upgrade huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "from langchain.llms import Petals\n",
        "from huggingface_hub import login\n",
        "from langchain import PromptTemplate, LLMChain"
      ],
      "metadata": {
        "id": "7y_lzgHyk7bZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get HuggingFace Apy Key"
      ],
      "metadata": {
        "id": "LfpW2XdKmkMi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "HUGGINGFACE_API_KEY = getpass()\n",
        "os.environ[\"HUGGINGFACE_API_KEY\"] = HUGGINGFACE_API_KEY"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CzcXcB8l5ju",
        "outputId": "11fc2409-e6b3-4cc7-afac-9fbc610dbaa9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "login(token=HUGGINGFACE_API_KEY,add_to_git_credential=True)\n",
        "# !huggingface-cli login --token HUGGINGFACE_API_KEY"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "reOpfYlFvDQG",
        "outputId": "7e65e139-8b41-48af-900c-1421f8f86e86"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token is valid (permission: read).\n",
            "Your token has been saved in your configured git credential helpers (store).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Llama-2-70b-chat-hf\n",
        "\n",
        "- Link to [information of model](https://huggingface.co/meta-llama/Llama-2-70b-hf)"
      ],
      "metadata": {
        "id": "loVoRoJbmrOA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "llm = Petals(model_name=\"meta-llama/Llama-2-70b-chat-hf\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "RGmyrnMomwA4",
        "outputId": "82532495-d2ff-45c6-ac52-1ffd835ca073"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Sep 07 08:26:21.475 [\u001b[1m\u001b[34mINFO\u001b[0m] Make sure you follow the LLaMA's terms of use: https://bit.ly/llama2-license for LLaMA 2, https://bit.ly/llama-license for LLaMA 1\n",
            "Sep 07 08:26:21.476 [\u001b[1m\u001b[34mINFO\u001b[0m] Using DHT prefix: Llama-2-70b-chat-hf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a prompt template"
      ],
      "metadata": {
        "id": "aHLOKcoowDZj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"Question: {question}\n",
        "\n",
        "Answer: Let's think step by step.\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(template=template, input_variables=[\"question\"])"
      ],
      "metadata": {
        "id": "MY6gZpRJnOPK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initiate and run LLMChain"
      ],
      "metadata": {
        "id": "QzUznLJAwIaD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm_chain = LLMChain(prompt=prompt, llm=llm)"
      ],
      "metadata": {
        "id": "JBGgQ6GVwFQA"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What NFL team won the Super Bowl in the year Justin Beiber was born?\""
      ],
      "metadata": {
        "id": "W1dJ8tmswX9M"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "complete_template = llm_chain.run(question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OM3RHMlLwN7l",
        "outputId": "4faa1459-1dd0-499c-af5f-96bdc43bc6a2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Sep 07 08:55:25.808 [\u001b[1m\u001b[34mINFO\u001b[0m] Route found: 0:40 via …CMBDje => 40:80 via …2mj7xE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 12.7 s, sys: 23.5 s, total: 36.2 s\n",
            "Wall time: 1min 17s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(complete_template)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfeFfKvT2nWk",
        "outputId": "a0dc29fc-dec4-456e-8822-eb80945eda2d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> Question: What NFL team won the Super Bowl in the year Justin Beiber was born?\n",
            "\n",
            "Answer: Let's think step by step. Justin Bieber was born in 1994. The Super Bowl that year was Super Bowl XXVIII. The Dallas Cowboys won that Super Bowl, defeating the Buffalo Bills.</s>\n"
          ]
        }
      ]
    }
  ]
}